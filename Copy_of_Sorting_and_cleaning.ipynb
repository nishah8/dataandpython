{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishah8/dataandpython/blob/main/Copy_of_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first.\n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g.\n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make\n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted*\n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score\n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cd3b1f-3393-4ebb-af50-c22efed28ee7"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel( 'https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true')\n",
        "print (df.head(5))\n",
        "print()\n",
        "sorteddf = df.sort_values(\"Happiness Score\")\n",
        "print (sorteddf)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Country          Region  Happiness Rank  Happiness Score  \\\n",
            "0  Switzerland  Western Europe               1            7.587   \n",
            "1      Iceland  Western Europe               2            7.561   \n",
            "2      Denmark  Western Europe               3            7.527   \n",
            "3       Norway  Western Europe               4            7.522   \n",
            "4       Canada   North America               5            7.427   \n",
            "\n",
            "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
            "0         0.03411                   1.39651  1.34951   \n",
            "1         0.04884                   1.30232  1.40223   \n",
            "2         0.03328                   1.32548  1.36058   \n",
            "3         0.03880                   1.45900  1.33095   \n",
            "4         0.03553                   1.32629  1.32261   \n",
            "\n",
            "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
            "0                   0.94143  0.66557                        0.41978   \n",
            "1                   0.94784  0.62877                        0.14145   \n",
            "2                   0.87464  0.64938                        0.48357   \n",
            "3                   0.88521  0.66973                        0.36503   \n",
            "4                   0.90563  0.63297                        0.32957   \n",
            "\n",
            "   Generosity  Dystopia Residual  \n",
            "0     0.29678            2.51738  \n",
            "1     0.43630            2.70201  \n",
            "2     0.34139            2.49204  \n",
            "3     0.34699            2.46531  \n",
            "4     0.45811            2.45176  \n",
            "\n",
            "         Country                           Region  Happiness Rank  \\\n",
            "157         Togo               Sub-Saharan Africa             158   \n",
            "156      Burundi               Sub-Saharan Africa             157   \n",
            "155        Syria  Middle East and Northern Africa             156   \n",
            "154        Benin               Sub-Saharan Africa             155   \n",
            "153       Rwanda               Sub-Saharan Africa             154   \n",
            "..           ...                              ...             ...   \n",
            "4         Canada                    North America               5   \n",
            "3         Norway                   Western Europe               4   \n",
            "2        Denmark                   Western Europe               3   \n",
            "1        Iceland                   Western Europe               2   \n",
            "0    Switzerland                   Western Europe               1   \n",
            "\n",
            "     Happiness Score  Standard Error  Economy (GDP per Capita)   Family  \\\n",
            "157            2.839         0.06727                   0.20868  0.13995   \n",
            "156            2.905         0.08658                   0.01530  0.41587   \n",
            "155            3.006         0.05015                   0.66320  0.47489   \n",
            "154            3.340         0.03656                   0.28665  0.35386   \n",
            "153            3.465         0.03464                   0.22208  0.77370   \n",
            "..               ...             ...                       ...      ...   \n",
            "4              7.427         0.03553                   1.32629  1.32261   \n",
            "3              7.522         0.03880                   1.45900  1.33095   \n",
            "2              7.527         0.03328                   1.32548  1.36058   \n",
            "1              7.561         0.04884                   1.30232  1.40223   \n",
            "0              7.587         0.03411                   1.39651  1.34951   \n",
            "\n",
            "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
            "157                   0.28443  0.36453                        0.10731   \n",
            "156                   0.22396  0.11850                        0.10062   \n",
            "155                   0.72193  0.15684                        0.18906   \n",
            "154                   0.31910  0.48450                        0.08010   \n",
            "153                   0.42864  0.59201                        0.55191   \n",
            "..                        ...      ...                            ...   \n",
            "4                     0.90563  0.63297                        0.32957   \n",
            "3                     0.88521  0.66973                        0.36503   \n",
            "2                     0.87464  0.64938                        0.48357   \n",
            "1                     0.94784  0.62877                        0.14145   \n",
            "0                     0.94143  0.66557                        0.41978   \n",
            "\n",
            "     Generosity  Dystopia Residual  \n",
            "157     0.16681            1.56726  \n",
            "156     0.19727            1.83302  \n",
            "155     0.47179            0.32858  \n",
            "154     0.18260            1.63328  \n",
            "153     0.22628            0.67042  \n",
            "..          ...                ...  \n",
            "4       0.45811            2.45176  \n",
            "3       0.34699            2.46531  \n",
            "2       0.34139            2.49204  \n",
            "1       0.43630            2.70201  \n",
            "0       0.29678            2.51738  \n",
            "\n",
            "[158 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows\n",
        "---\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order\n",
        "2. display the first 5 rows of sorted data\n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b102ec-2d68-42a1-f624-c0aaa00e26f0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel( 'https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true')\n",
        "#question says economy then life expectancy but desired output comes out other way around\n",
        "\n",
        "sortdf = df.sort_values(by = [\"Health (Life Expectancy)\",\"Economy (GDP per Capita)\"])\n",
        "print(sortdf.head(5))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Country              Region  Happiness Rank  \\\n",
            "122              Sierra Leone  Sub-Saharan Africa             123   \n",
            "127                  Botswana  Sub-Saharan Africa             128   \n",
            "147  Central African Republic  Sub-Saharan Africa             148   \n",
            "100                 Swaziland  Sub-Saharan Africa             101   \n",
            "96                    Lesotho  Sub-Saharan Africa              97   \n",
            "\n",
            "     Happiness Score  Standard Error  Economy (GDP per Capita)   Family  \\\n",
            "122            4.507         0.07068                   0.33024  0.95571   \n",
            "127            4.332         0.04934                   0.99355  1.10464   \n",
            "147            3.678         0.06112                   0.07850  0.00000   \n",
            "100            4.867         0.08742                   0.71206  1.07284   \n",
            "96             4.898         0.09438                   0.37545  1.04103   \n",
            "\n",
            "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
            "122                   0.00000  0.40840                        0.08786   \n",
            "127                   0.04776  0.49495                        0.12474   \n",
            "147                   0.06699  0.48879                        0.08289   \n",
            "100                   0.07566  0.30658                        0.03060   \n",
            "96                    0.07612  0.31767                        0.12504   \n",
            "\n",
            "     Generosity  Dystopia Residual  \n",
            "122     0.21488            2.51009  \n",
            "127     0.10461            1.46181  \n",
            "147     0.23835            2.72230  \n",
            "100     0.18259            2.48676  \n",
            "96      0.16388            2.79832  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order\n",
        "---\n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "136, 117, 95, 101, 111 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9909b158-9820-42fa-8a7d-21bc812a44c2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel( 'https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true')\n",
        "freedom_trustsort = df.sort_values(by=['Freedom','Trust (Government Corruption)'], ascending=False)\n",
        "print(freedom_trustsort[['Country','Region']].tail(5))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Country                           Region\n",
            "136                  Angola               Sub-Saharan Africa\n",
            "117                   Sudan               Sub-Saharan Africa\n",
            "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
            "101                  Greece                   Western Europe\n",
            "111                    Iraq  Middle East and Northern Africa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values\n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values\n",
        "---\n",
        "\n",
        "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
        "2. check if any NA values exist in the dataframe and print the result\n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84ed35d-e71d-4637-b983-7e353e6568c5"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print (df.isnull().values.any())\n",
        "print()\n",
        "\n",
        "df.info()\n",
        "print()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values\n",
        "---\n",
        "\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. remove all NA values across whole dataframe\n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0d83f0-d2e8-49cd-8cd7-45353625f662"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "x = df.dropna(subset = [\"life_satisfaction\"])\n",
        "print(x.info())\n",
        "print()\n",
        "\n",
        "y = df.dropna()\n",
        "print(y.info())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 352 entries, 613 to 1019\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               352 non-null    object \n",
            " 1   area               352 non-null    object \n",
            " 2   date               352 non-null    object \n",
            " 3   median_salary      347 non-null    float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        352 non-null    object \n",
            " 6   recycling_pct      328 non-null    object \n",
            " 7   population_size    350 non-null    float64\n",
            " 8   number_of_jobs     352 non-null    float64\n",
            " 9   area_size          272 non-null    float64\n",
            " 10  no_of_houses       272 non-null    float64\n",
            " 11  borough_flag       352 non-null    int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 35.8+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 267 entries, 613 to 1013\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               267 non-null    object \n",
            " 1   area               267 non-null    object \n",
            " 2   date               267 non-null    object \n",
            " 3   median_salary      267 non-null    float64\n",
            " 4   life_satisfaction  267 non-null    float64\n",
            " 5   mean_salary        267 non-null    object \n",
            " 6   recycling_pct      267 non-null    object \n",
            " 7   population_size    267 non-null    float64\n",
            " 8   number_of_jobs     267 non-null    float64\n",
            " 9   area_size          267 non-null    float64\n",
            " 10  no_of_houses       267 non-null    float64\n",
            " 11  borough_flag       267 non-null    int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 27.1+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])`\n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries\n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8572d0-10c5-49b8-e012-081c4be0630f"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "areadup = df.drop_duplicates(subset = ['area'])\n",
        "print(areadup)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         code                      area        date  median_salary  \\\n",
            "0   E09000001            city of london  1999-12-01        33020.0   \n",
            "1   E09000002      barking and dagenham  1999-12-01        21480.0   \n",
            "2   E09000003                    barnet  1999-12-01        19568.0   \n",
            "3   E09000004                    bexley  1999-12-01        18621.0   \n",
            "4   E09000005                     brent  1999-12-01        18532.0   \n",
            "5   E09000006                   bromley  1999-12-01        16720.0   \n",
            "6   E09000007                    camden  1999-12-01        23677.0   \n",
            "7   E09000008                   croydon  1999-12-01        19563.0   \n",
            "8   E09000009                    ealing  1999-12-01        20580.0   \n",
            "9   E09000010                   enfield  1999-12-01        19289.0   \n",
            "10  E09000011                 greenwich  1999-12-01        21236.0   \n",
            "11  E09000012                   hackney  1999-12-01        23249.0   \n",
            "12  E09000013    hammersmith and fulham  1999-12-01        25000.0   \n",
            "13  E09000014                  haringey  1999-12-01        18783.0   \n",
            "14  E09000015                    harrow  1999-12-01        20596.0   \n",
            "15  E09000016                  havering  1999-12-01        17165.0   \n",
            "16  E09000017                hillingdon  1999-12-01        24002.0   \n",
            "17  E09000018                  hounslow  1999-12-01        20155.0   \n",
            "18  E09000019                 islington  1999-12-01        25113.0   \n",
            "19  E09000020    kensington and chelsea  1999-12-01        20646.0   \n",
            "20  E09000021      kingston upon thames  1999-12-01        19302.0   \n",
            "21  E09000022                   lambeth  1999-12-01        23151.0   \n",
            "22  E09000023                  lewisham  1999-12-01        20580.0   \n",
            "23  E09000024                    merton  1999-12-01        18962.0   \n",
            "24  E09000025                    newham  1999-12-01        18862.0   \n",
            "25  E09000026                 redbridge  1999-12-01        19580.0   \n",
            "26  E09000027      richmond upon thames  1999-12-01        22321.0   \n",
            "27  E09000028                 southwark  1999-12-01        22784.0   \n",
            "28  E09000029                    sutton  1999-12-01        19582.0   \n",
            "29  E09000030             tower hamlets  1999-12-01        26376.0   \n",
            "30  E09000031            waltham forest  1999-12-01        18547.0   \n",
            "31  E09000032                wandsworth  1999-12-01        21321.0   \n",
            "32  E09000033               westminster  1999-12-01        24447.0   \n",
            "33  E12000001                north east  1999-12-01        16282.0   \n",
            "34  E12000002                north west  1999-12-01        16977.0   \n",
            "35  E12000003  yorkshire and the humber  1999-12-01        16527.0   \n",
            "36  E12000004             east midlands  1999-12-01        16392.0   \n",
            "37  E12000005             west midlands  1999-12-01        17000.0   \n",
            "38  E12000006                      east  1999-12-01        18000.0   \n",
            "39  E12000007                    london  1999-12-01        22487.0   \n",
            "40  E12000008                south east  1999-12-01        18737.0   \n",
            "41  E12000009                south west  1999-12-01        16727.0   \n",
            "42  E13000001              inner london  1999-12-01            NaN   \n",
            "43  E13000002              outer london  1999-12-01            NaN   \n",
            "44  E92000001                   england  1999-12-01        17939.0   \n",
            "45  K02000001            united kingdom  1999-12-01        17803.0   \n",
            "46  K03000001             great britain  1999-12-01        17866.0   \n",
            "47  K04000001         england and wales  1999-12-01        17974.0   \n",
            "48  N92000002          northern ireland  1999-12-01        15798.0   \n",
            "49  S92000003                  scotland  1999-12-01        16914.0   \n",
            "50  W92000004                     wales  1999-12-01        16457.0   \n",
            "\n",
            "    life_satisfaction mean_salary recycling_pct  population_size  \\\n",
            "0                 NaN       48922             0           6581.0   \n",
            "1                 NaN       23620             3         162444.0   \n",
            "2                 NaN       23128             8         313469.0   \n",
            "3                 NaN       21386            18         217458.0   \n",
            "4                 NaN       20911             6         260317.0   \n",
            "5                 NaN       21293            13         294902.0   \n",
            "6                 NaN       30249            13         190003.0   \n",
            "7                 NaN       22205            13         332066.0   \n",
            "8                 NaN       25046            12         302252.0   \n",
            "9                 NaN       21006             9         272731.0   \n",
            "10                NaN       22263             4         212168.0   \n",
            "11                NaN       39629             2         199087.0   \n",
            "12                NaN       28555             7         160634.0   \n",
            "13                NaN       21683             5         218559.0   \n",
            "14                NaN       22824            10         207909.0   \n",
            "15                NaN       18786             8         225712.0   \n",
            "16                NaN       28854            11         245053.0   \n",
            "17                NaN       24602            14         214298.0   \n",
            "18                NaN       34180             2         175717.0   \n",
            "19                NaN       28074            13         147678.0   \n",
            "20                NaN       22967            18         146003.0   \n",
            "21                NaN       27930             8         266817.0   \n",
            "22                NaN       23283             4         250310.0   \n",
            "23                NaN       21867            11         185062.0   \n",
            "24                NaN       20580             3         240517.0   \n",
            "25                NaN       22087             8         238138.0   \n",
            "26                NaN       25832            na         172782.0   \n",
            "27                NaN       26994             3         247853.0   \n",
            "28                NaN       22725            27         179375.0   \n",
            "29                NaN       37524             3         193507.0   \n",
            "30                NaN       19888             9         221057.0   \n",
            "31                NaN       24707             7         264220.0   \n",
            "32                NaN       36167             7         189233.0   \n",
            "33                NaN       18351             5        2550314.0   \n",
            "34                NaN       19609             7        6773115.0   \n",
            "35                NaN       18977             7        4956325.0   \n",
            "36                NaN       18864            11        4152443.0   \n",
            "37                NaN       19686             9        5271959.0   \n",
            "38                NaN       20866            14        5338722.0   \n",
            "39                NaN       29640             9        7153912.0   \n",
            "40                NaN       22361            15        7955124.0   \n",
            "41                NaN       19203            14        4880958.0   \n",
            "42                NaN           -           NaN        2750716.0   \n",
            "43                NaN           -           NaN        4403196.0   \n",
            "44                NaN       21561            10       49032872.0   \n",
            "45                NaN       21314           NaN       58684427.0   \n",
            "46                NaN       21379           NaN       57005421.0   \n",
            "47                NaN       21549           NaN       51933471.0   \n",
            "48                NaN       19093           NaN        1679006.0   \n",
            "49                NaN       19667           NaN        5071950.0   \n",
            "50                NaN       18486           NaN        2900599.0   \n",
            "\n",
            "    number_of_jobs  area_size  no_of_houses  borough_flag  \n",
            "0              NaN        NaN           NaN             1  \n",
            "1              NaN        NaN           NaN             1  \n",
            "2              NaN        NaN           NaN             1  \n",
            "3              NaN        NaN           NaN             1  \n",
            "4              NaN        NaN           NaN             1  \n",
            "5              NaN        NaN           NaN             1  \n",
            "6              NaN        NaN           NaN             1  \n",
            "7              NaN        NaN           NaN             1  \n",
            "8              NaN        NaN           NaN             1  \n",
            "9              NaN        NaN           NaN             1  \n",
            "10             NaN        NaN           NaN             1  \n",
            "11             NaN        NaN           NaN             1  \n",
            "12             NaN        NaN           NaN             1  \n",
            "13             NaN        NaN           NaN             1  \n",
            "14             NaN        NaN           NaN             1  \n",
            "15             NaN        NaN           NaN             1  \n",
            "16             NaN        NaN           NaN             1  \n",
            "17             NaN        NaN           NaN             1  \n",
            "18             NaN        NaN           NaN             1  \n",
            "19             NaN        NaN           NaN             1  \n",
            "20             NaN        NaN           NaN             1  \n",
            "21             NaN        NaN           NaN             1  \n",
            "22             NaN        NaN           NaN             1  \n",
            "23             NaN        NaN           NaN             1  \n",
            "24             NaN        NaN           NaN             1  \n",
            "25             NaN        NaN           NaN             1  \n",
            "26             NaN        NaN           NaN             1  \n",
            "27             NaN        NaN           NaN             1  \n",
            "28             NaN        NaN           NaN             1  \n",
            "29             NaN        NaN           NaN             1  \n",
            "30             NaN        NaN           NaN             1  \n",
            "31             NaN        NaN           NaN             1  \n",
            "32             NaN        NaN           NaN             1  \n",
            "33             NaN        NaN           NaN             0  \n",
            "34             NaN        NaN           NaN             0  \n",
            "35             NaN        NaN           NaN             0  \n",
            "36             NaN        NaN           NaN             0  \n",
            "37             NaN        NaN           NaN             0  \n",
            "38             NaN        NaN           NaN             0  \n",
            "39             NaN        NaN           NaN             0  \n",
            "40             NaN        NaN           NaN             0  \n",
            "41             NaN        NaN           NaN             0  \n",
            "42             NaN        NaN           NaN             0  \n",
            "43             NaN        NaN           NaN             0  \n",
            "44             NaN        NaN           NaN             0  \n",
            "45             NaN        NaN           NaN             0  \n",
            "46             NaN        NaN           NaN             0  \n",
            "47             NaN        NaN           NaN             0  \n",
            "48             NaN        NaN           NaN             0  \n",
            "49             NaN        NaN           NaN             0  \n",
            "50             NaN        NaN           NaN             0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f384ea80-6d07-444a-b07c-b0a0098c6009"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "def normalise_income(df):\n",
        "  if df['median_salary'] < 27441:\n",
        "    return 1\n",
        "  elif df['median_salary'] < 30932:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "df[\"median_salary\"] = df.apply(normalise_income, axis=1)\n",
        "print('max value in median salary column:',df['median_salary'].max(),'\\nmin value in median salary column:',df['median_salary'].min())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max value in median salary column: 3 \n",
            "min value in median salary column: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056aa018-f866-4b63-e7e1-1c75c641bf65"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df.describe())\n",
        "\n",
        "def normalise_jobs(df):\n",
        "  if df['number_of_jobs'] < 1.570000e+05:\n",
        "    return 1\n",
        "  elif df['number_of_jobs'] < 2.217000e+06:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "df[\"number_of_jobs\"] = df.apply(normalise_jobs, axis=1)\n",
        "print()\n",
        "print('max value in number of jobs column:',df['number_of_jobs'].max(),'\\nmin value in number of jobs column:',df['number_of_jobs'].min())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       median_salary  life_satisfaction  population_size  number_of_jobs  \\\n",
            "count    1049.000000         352.000000     1.018000e+03    9.310000e+02   \n",
            "mean    27977.792183           7.485057     6.042576e+06    3.188095e+06   \n",
            "std      6412.807487           0.198451     1.526810e+07    8.058302e+06   \n",
            "min     15684.000000           7.000000     6.581000e+03    4.700000e+04   \n",
            "25%     23857.000000           7.350000     2.243458e+05    9.450000e+04   \n",
            "50%     27441.000000           7.510000     2.946035e+05    1.570000e+05   \n",
            "75%     30932.000000           7.640000     4.630098e+06    2.217000e+06   \n",
            "max     61636.000000           7.960000     6.643555e+07    3.575000e+07   \n",
            "\n",
            "          area_size  no_of_houses  borough_flag  \n",
            "count  6.660000e+02  6.660000e+02   1071.000000  \n",
            "mean   3.724903e+05  8.814682e+05      0.647059  \n",
            "std    2.157060e+06  3.690376e+06      0.478108  \n",
            "min    3.150000e+02  5.009000e+03      0.000000  \n",
            "25%    2.960000e+03  8.763550e+04      0.000000  \n",
            "50%    4.323000e+03  1.024020e+05      1.000000  \n",
            "75%    8.220000e+03  1.262760e+05      1.000000  \n",
            "max    1.330373e+07  2.417217e+07      1.000000  \n",
            "max value in number of jobs column: 3 \n",
            "min value in number of jobs column: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aaf4c7f-5a0f-4a9c-d903-d07581eab21c"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "def normalise_housing(df):\n",
        "  if df['no_of_houses'] < 1.024020e+05:\n",
        "    return 1\n",
        "  elif df['no_of_houses'] < 1.262760e+05:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "df[\"housing_volume\"] = df.apply(normalise_housing, axis=1)\n",
        "print()\n",
        "print('max value in housing volume column:',df['housing_volume'].max(),'\\nmin value in housing volume column:',df['housing_volume'].min())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "max value in housing volume column: 3 \n",
            "min value in housing volume column: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd48821-e314-4693-cb98-dfa7a0e5de33"
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "def normalise_areasize(df):\n",
        "  if df['area_size'] < 3.724903e+05:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "df[\"area_size_normalised\"] = df.apply(normalise_areasize, axis=1)\n",
        "print()\n",
        "print('first instance of value being 1:',df[df['area_size_normalised']==1].first_valid_index(),'\\nfirst instance of value being 0:',df[df['area_size_normalised']== 0].first_valid_index())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "first instance of value being 1: 0 \n",
            "first instance of value being 0: 102\n"
          ]
        }
      ]
    }
  ]
}